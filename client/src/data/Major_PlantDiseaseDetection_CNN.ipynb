{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "V28"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Part 1 - Importing Dataset"
      ],
      "metadata": {
        "id": "W4NJHwspwYVv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Importing necessary libraries from TensorFlow\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing import image\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "wuqd3xjTy2Ta"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Mount Google Drive to access Kaggle API key (kaggle.json)\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h4qcMm-T7IrY",
        "outputId": "d6b5376a-eef4-478f-9508-efeba8e5f448"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 2: Configure Kaggle API access by copying kaggle.json from Google Drive\n",
        "\n",
        "!mkdir ~/.kaggle/                             # Create a Kaggle folder\n",
        "!cp \"/content/drive/MyDrive/kaggle.json\" ~/.kaggle/kaggle.json  # Replace with your path to kaggle.json\n",
        "!chmod 600 ~/.kaggle/kaggle.json               # Secure the permissions for the file\n",
        "\n",
        "# Step 3: Download the dataset from Kaggle using Kaggle API\n",
        "\n",
        "!kaggle datasets download vipoooool/new-plant-diseases-dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pEuZx0hq7ImL",
        "outputId": "d4b94686-3bdc-49ce-e425-265a45c6efb6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset URL: https://www.kaggle.com/datasets/vipoooool/new-plant-diseases-dataset\n",
            "License(s): copyright-authors\n",
            "Downloading new-plant-diseases-dataset.zip to /content\n",
            "100% 2.70G/2.70G [00:20<00:00, 202MB/s]\n",
            "100% 2.70G/2.70G [00:20<00:00, 139MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 4: Unzip the dataset\n",
        "\n",
        "from zipfile import ZipFile\n",
        "zippedFile = \"/content/new-plant-diseases-dataset.zip\"  # The path of the downloaded zip file\n",
        "\n",
        "# Extract the contents of the zip file\n",
        "with ZipFile(zippedFile, 'r') as zip_ref:\n",
        "    zip_ref.extractall('/content')  # Extract all files into the content folder\n",
        "    zip_ref.close()\n",
        "\n",
        "# Step 5: Define the paths for train and validation directories after extraction\n",
        "\n",
        "train_dir = '/content/New Plant Diseases Dataset(Augmented)/New Plant Diseases Dataset(Augmented)/train'\n",
        "valid_dir = '/content/New Plant Diseases Dataset(Augmented)/New Plant Diseases Dataset(Augmented)/valid'"
      ],
      "metadata": {
        "id": "pv4V9zMn7IgL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Part 2 - Preprocessing"
      ],
      "metadata": {
        "id": "wdkpN8yAwhCe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 6: Data Preprocessing using ImageDataGenerator\n",
        "\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# Initialize the ImageDataGenerator for training set with augmentations\n",
        "train_datagen = ImageDataGenerator(rescale=1./255,\n",
        "                                   shear_range=0.2,\n",
        "                                   zoom_range=0.2,\n",
        "                                   horizontal_flip=True)\n",
        "\n",
        "# Initialize the ImageDataGenerator for validation set (only rescaling)\n",
        "valid_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "# Load the training data\n",
        "train_set = train_datagen.flow_from_directory(train_dir,\n",
        "                                              target_size=(64, 64),\n",
        "                                              batch_size=32,\n",
        "                                              class_mode='categorical')  # assuming multiple classes\n",
        "\n",
        "# Load the validation data\n",
        "valid_set = valid_datagen.flow_from_directory(valid_dir,\n",
        "                                              target_size=(64, 64),\n",
        "                                              batch_size=32,\n",
        "                                              class_mode='categorical')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i53UNvti7Ia_",
        "outputId": "f4483613-d77b-4e16-ad09-2dcfb75b7057"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 70295 images belonging to 38 classes.\n",
            "Found 17572 images belonging to 38 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Part 3 - Model"
      ],
      "metadata": {
        "id": "A1DTJNxlv9f7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Building the CNN Model"
      ],
      "metadata": {
        "id": "i5RFtxExv3WG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 7: Build the CNN Model\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "# Initialize the CNN model\n",
        "cnn = tf.keras.models.Sequential()\n",
        "\n",
        "# Add the layers: Convolution, MaxPooling, Flattening, Dense, etc.\n",
        "cnn.add(tf.keras.layers.Conv2D(filters=32, kernel_size=3, activation='relu', input_shape=[64, 64, 3]))\n",
        "cnn.add(tf.keras.layers.MaxPooling2D(pool_size=2, strides=2))\n",
        "\n",
        "cnn.add(tf.keras.layers.Conv2D(filters=32, kernel_size=3, activation='relu'))\n",
        "cnn.add(tf.keras.layers.MaxPooling2D(pool_size=2, strides=2))\n",
        "\n",
        "cnn.add(tf.keras.layers.Flatten())\n",
        "cnn.add(tf.keras.layers.Dense(units=128, activation='relu'))\n",
        "cnn.add(tf.keras.layers.Dense(units=38, activation='softmax'))  # Assuming 38 classes in the plant disease dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BbDZ_wXI7IVp",
        "outputId": "c6363aa8-c146-4d21-dac2-0cd2a75b10a0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training the Model"
      ],
      "metadata": {
        "id": "lrN55bxYvy8C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 8: Compile the CNN\n",
        "\n",
        "cnn.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "zKG4tcQ87IOh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 9: Train the model\n",
        "\n",
        "cnn.fit(x=train_set, validation_data=valid_set, epochs=25)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lV0GLa6E7fnT",
        "outputId": "5599be4d-9c59-450e-81b8-48d61c6ae25c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/25\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m2197/2197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m510s\u001b[0m 231ms/step - accuracy: 0.4802 - loss: 1.8318 - val_accuracy: 0.7290 - val_loss: 0.8866\n",
            "Epoch 2/25\n",
            "\u001b[1m2197/2197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m474s\u001b[0m 216ms/step - accuracy: 0.7992 - loss: 0.6331 - val_accuracy: 0.7586 - val_loss: 0.7931\n",
            "Epoch 3/25\n",
            "\u001b[1m2197/2197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m469s\u001b[0m 213ms/step - accuracy: 0.8496 - loss: 0.4648 - val_accuracy: 0.8215 - val_loss: 0.5921\n",
            "Epoch 4/25\n",
            "\u001b[1m2197/2197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m459s\u001b[0m 209ms/step - accuracy: 0.8755 - loss: 0.3850 - val_accuracy: 0.8553 - val_loss: 0.4564\n",
            "Epoch 5/25\n",
            "\u001b[1m2197/2197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m513s\u001b[0m 214ms/step - accuracy: 0.8945 - loss: 0.3243 - val_accuracy: 0.8729 - val_loss: 0.4099\n",
            "Epoch 6/25\n",
            "\u001b[1m2197/2197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m464s\u001b[0m 211ms/step - accuracy: 0.9069 - loss: 0.2879 - val_accuracy: 0.8821 - val_loss: 0.3781\n",
            "Epoch 7/25\n",
            "\u001b[1m2197/2197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m476s\u001b[0m 216ms/step - accuracy: 0.9107 - loss: 0.2685 - val_accuracy: 0.8660 - val_loss: 0.4449\n",
            "Epoch 8/25\n",
            "\u001b[1m2197/2197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m493s\u001b[0m 212ms/step - accuracy: 0.9204 - loss: 0.2385 - val_accuracy: 0.8802 - val_loss: 0.3877\n",
            "Epoch 9/25\n",
            "\u001b[1m2197/2197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m499s\u001b[0m 211ms/step - accuracy: 0.9299 - loss: 0.2093 - val_accuracy: 0.9108 - val_loss: 0.2828\n",
            "Epoch 10/25\n",
            "\u001b[1m2197/2197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m456s\u001b[0m 208ms/step - accuracy: 0.9335 - loss: 0.1968 - val_accuracy: 0.8618 - val_loss: 0.4618\n",
            "Epoch 11/25\n",
            "\u001b[1m2197/2197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m502s\u001b[0m 208ms/step - accuracy: 0.9340 - loss: 0.1962 - val_accuracy: 0.8928 - val_loss: 0.3583\n",
            "Epoch 12/25\n",
            "\u001b[1m2197/2197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m460s\u001b[0m 209ms/step - accuracy: 0.9404 - loss: 0.1789 - val_accuracy: 0.9123 - val_loss: 0.2879\n",
            "Epoch 13/25\n",
            "\u001b[1m2197/2197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m495s\u001b[0m 206ms/step - accuracy: 0.9450 - loss: 0.1635 - val_accuracy: 0.9054 - val_loss: 0.3209\n",
            "Epoch 14/25\n",
            "\u001b[1m2197/2197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m455s\u001b[0m 207ms/step - accuracy: 0.9449 - loss: 0.1618 - val_accuracy: 0.9169 - val_loss: 0.2814\n",
            "Epoch 15/25\n",
            "\u001b[1m2197/2197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m467s\u001b[0m 212ms/step - accuracy: 0.9470 - loss: 0.1584 - val_accuracy: 0.9109 - val_loss: 0.2931\n",
            "Epoch 16/25\n",
            "\u001b[1m2197/2197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m469s\u001b[0m 213ms/step - accuracy: 0.9517 - loss: 0.1457 - val_accuracy: 0.9171 - val_loss: 0.2778\n",
            "Epoch 17/25\n",
            "\u001b[1m2197/2197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m491s\u001b[0m 208ms/step - accuracy: 0.9546 - loss: 0.1386 - val_accuracy: 0.9014 - val_loss: 0.3535\n",
            "Epoch 18/25\n",
            "\u001b[1m2197/2197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m475s\u001b[0m 216ms/step - accuracy: 0.9546 - loss: 0.1365 - val_accuracy: 0.9161 - val_loss: 0.2974\n",
            "Epoch 19/25\n",
            "\u001b[1m2197/2197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m480s\u001b[0m 218ms/step - accuracy: 0.9553 - loss: 0.1317 - val_accuracy: 0.9276 - val_loss: 0.2497\n",
            "Epoch 20/25\n",
            "\u001b[1m2197/2197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m473s\u001b[0m 215ms/step - accuracy: 0.9560 - loss: 0.1283 - val_accuracy: 0.9019 - val_loss: 0.3741\n",
            "Epoch 21/25\n",
            "\u001b[1m2197/2197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m458s\u001b[0m 208ms/step - accuracy: 0.9589 - loss: 0.1204 - val_accuracy: 0.8989 - val_loss: 0.3686\n",
            "Epoch 22/25\n",
            "\u001b[1m2197/2197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m516s\u001b[0m 214ms/step - accuracy: 0.9576 - loss: 0.1250 - val_accuracy: 0.9238 - val_loss: 0.2761\n",
            "Epoch 23/25\n",
            "\u001b[1m2197/2197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m490s\u001b[0m 209ms/step - accuracy: 0.9611 - loss: 0.1176 - val_accuracy: 0.9267 - val_loss: 0.2633\n",
            "Epoch 24/25\n",
            "\u001b[1m2197/2197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m494s\u001b[0m 205ms/step - accuracy: 0.9602 - loss: 0.1192 - val_accuracy: 0.9384 - val_loss: 0.2185\n",
            "Epoch 25/25\n",
            "\u001b[1m2197/2197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m513s\u001b[0m 210ms/step - accuracy: 0.9624 - loss: 0.1168 - val_accuracy: 0.9294 - val_loss: 0.2527\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7a97d578aa10>"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Saving the model"
      ],
      "metadata": {
        "id": "c5q6ZnErvpQ7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 10: Save the trained model\n",
        "\n",
        "cnn.save('/content/plant_disease_model.h5')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u3cooN4S7jXl",
        "outputId": "45f79772-d584-4e19-ea57-ef961d3257e0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cnn.save('/content/plant_disease_model.keras')"
      ],
      "metadata": {
        "id": "Hle14jvir1ou"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Part 4 - Plotting confusion matrix for accuracy"
      ],
      "metadata": {
        "id": "kk2k2bN1vhHL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# Load the trained model\n",
        "model = tf.keras.models.load_model('/content/plant_disease_model.h5')"
      ],
      "metadata": {
        "id": "lz9zbomiQoea"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score\n",
        "\n",
        "# Initialize storage for images and labels\n",
        "selected_images = []\n",
        "selected_labels = []\n",
        "\n",
        "# Extract 100 images per class from the validation set\n",
        "class_count = {key: 0 for key in valid_set.class_indices.keys()}  # Count to track 100 images per class\n",
        "\n",
        "for images, labels in valid_set:\n",
        "    for i, label in enumerate(labels):\n",
        "        class_name = list(valid_set.class_indices.keys())[np.argmax(label)]\n",
        "\n",
        "        # Add 100 images per class\n",
        "        if class_count[class_name] < 100:\n",
        "            selected_images.append(images[i])\n",
        "            selected_labels.append(label)\n",
        "            class_count[class_name] += 1\n",
        "\n",
        "        # Break the loop once we have 100 images for each class\n",
        "        if all(count >= 100 for count in class_count.values()):\n",
        "            break\n",
        "    if all(count >= 100 for count in class_count.values()):\n",
        "        break\n",
        "\n",
        "# Convert selected images and labels to numpy arrays\n",
        "selected_images = np.array(selected_images)\n",
        "selected_labels = np.array(selected_labels)\n",
        "\n",
        "# Step 2: Predict on the selected validation images\n",
        "predictions = model.predict(selected_images)\n",
        "predicted_classes = np.argmax(predictions, axis=1)\n",
        "\n",
        "# Convert one-hot encoded true labels to integers\n",
        "true_classes = np.argmax(selected_labels, axis=1)\n",
        "\n",
        "# Step 3: Calculate accuracy and confusion matrix\n",
        "accuracy = accuracy_score(true_classes, predicted_classes) * 100\n",
        "print(f'Accuracy: {accuracy:.2f}%')\n",
        "\n",
        "# Step 4: Generate confusion matrix\n",
        "cm = confusion_matrix(true_classes, predicted_classes)\n",
        "\n",
        "# Plot the confusion matrix using Seaborn\n",
        "plt.figure(figsize=(12, 10))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
        "            xticklabels=valid_set.class_indices.keys(),\n",
        "            yticklabels=valid_set.class_indices.keys())\n",
        "plt.title('Confusion Matrix')\n",
        "plt.xlabel('Predicted Labels')\n",
        "plt.ylabel('True Labels')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "krO9ToJuJ957"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}